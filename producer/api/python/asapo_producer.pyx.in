#distutils: language=c++
#cython: language_level=2

cimport asapo_producer
import numpy as np
cimport numpy as np
import json
from cpython.version cimport PY_MAJOR_VERSION
from libcpp.memory cimport unique_ptr
from cpython.ref cimport PyObject,Py_XINCREF,Py_XDECREF
import atexit

np.import_array()

DEFAULT_INGEST_MODE = kDefaultIngestMode
INGEST_MODE_TRANSFER_DATA = kTransferData
INGEST_MODE_TRANSFER_METADATA_ONLY = kTransferMetaDataOnly
INGEST_MODE_STORE_IN_FILESYSTEM = kStoreInFilesystem
INGEST_MODE_STORE_IN_DATABASE = kStoreInDatabase
INGEST_MODE_WRITE_RAW_DATA_TO_OFFLINE_FS = kWriteRawDataToOffline

cdef extern from "numpy/ndarraytypes.h":
    void PyArray_ENABLEFLAGS(np.ndarray arr, int flags)

cdef str _str(b):
    if PY_MAJOR_VERSION < 3:
        return b
    return b.decode("utf-8")

cdef bytes _bytes(s):
    if type(s) is bytes:
        return s

    elif isinstance(s, unicode):
        return (<unicode>s).encode('utf-8')

    else:
        raise TypeError("Could not convert to unicode.")
cdef MetaIngestOp mode_to_c(mode):
    if mode == 'replace':
        return kReplace
    elif mode == 'update':
        return kUpdate
    elif mode == 'insert':
        return kInsert
    else:
        raise TypeError("Could not convert to unicode.")


class AsapoProducerError(Exception):
  pass

class AsapoWrongInputError(AsapoProducerError):
  pass

class AsapoLocalIOError(AsapoProducerError):
  pass

class AsapoTimeOutError(AsapoProducerError):
  pass

class AsapoServerWarning(AsapoProducerError):
  pass

class AsapoRequestsPoolIsFull(AsapoProducerError):
  pass

class AsapoUnsupportedClientError(AsapoProducerError):
  pass

cdef python_exception_from_error(Error& err):
    error_string =  _str(err.get().Explain())
    if err == kTimeout:
                return AsapoTimeOutError(error_string)
    elif err == kWrongInput:
            return AsapoWrongInputError(error_string)
    elif err == kLocalIOError:
            return AsapoLocalIOError(error_string)
    elif err == kServerWarning:
            return AsapoServerWarning(error_string)
    elif err == kRequestPoolIsFull:
            return AsapoRequestsPoolIsFull(error_string)
    elif err == kUnsupportedClient:
            raise AsapoUnsupportedClientError(error_string)
    else:
        return AsapoProducerError(error_string)

cdef throw_exception(Error& err):
    raise python_exception_from_error(err)

cdef void* data_pointer_nparray(data) except? NULL:
  if data is None:
    return <void*>NULL
  data_char = data.view(np.int8)
  try:
    data_char.shape=(-1)
  except:
    raise AsapoWrongInputError("cannot do no-copy flatten - non-contiguous array?")
  cdef char[::1] arr_memview = data_char
  return <void*>&arr_memview[0]

cdef void* data_pointer_bytes(data):
  if data is None:
    return <void*>NULL
  cdef const unsigned char[::1] arr_memview = data
  return <void*>&arr_memview[0]

cdef class PyProducer:
    cdef unique_ptr[Producer] c_producer
    def __init__(self):
        atexit.register(self.cleanup)
    def set_log_level(self,level):
         cdef LogLevel log_level
         log_level = LogLevel_Info
         if level == "debug" :
            log_level = LogLevel_Debug
         elif level == "info" :
            log_level = LogLevel_Info
         elif level == "error" :
            log_level = LogLevel_Error
         elif level == "none" :
            log_level = LogLevel_None
         elif level == "warn" :
            log_level = LogLevel_Warning
         else:
            print("wrong loglevel mode: "+ level)
            return
         self.c_producer.get().SetLogLevel(log_level)
    def get_version_info(self, from_server = "true"):
        cdef string client_info,server_info
        cdef bool supported
        cdef string* p_server_info =  &server_info if from_server else <string*>NULL
        cdef bool* p_supported =  &supported if from_server else <bool*>NULL
        cdef Error err
        with nogil:
            err =  self.c_producer.get().GetVersionInfo(&client_info,p_server_info,p_supported)
        if err:
            throw_exception(err)
        version = {}
        if from_server:
            return {'client': _str(client_info), 'server': _str(server_info), 'supported': supported}
        else:
            return {'client': _str(client_info)}
    def __send_np_array(self, id, exposed_path,data, user_meta=None,dataset=None,stream="default",ingest_mode = DEFAULT_INGEST_MODE,callback=None, auto_id = False):
        cdef MessageHeader message_header = self.create_message_header(id,exposed_path,user_meta,dataset,ingest_mode,auto_id)
        if data is None:
            message_header.data_size = 0
        else:
            message_header.data_size = data.nbytes
        err = self.c_producer.get().Send__(message_header, data_pointer_nparray(data),ingest_mode,_bytes(stream),
            unwrap_callback_with_memory(<RequestCallbackCythonMemory>self.c_callback_ndarr,
             <void*>self,<void*>callback, <void*>data))
        if err:
            throw_exception(err)
        if data is not None:
          if data.base is not None:
            Py_XINCREF(<PyObject*>data.base)
          else:
            Py_XINCREF(<PyObject*>data)
        if callback != None:
            Py_XINCREF(<PyObject*>callback)
        return
    cdef MessageHeader create_message_header(self,uint64_t id, exposed_path,user_meta,dataset,ingest_mode,auto_id):
        cdef MessageHeader message_header
        message_header.message_id = id
        message_header.file_name = _bytes(exposed_path)
        message_header.user_metadata = _bytes(user_meta) if user_meta!=None else ""
        message_header.auto_id = auto_id
        if dataset == None:
            message_header.dataset_substream = 0
            message_header.dataset_size = 0
        else:
            message_header.dataset_substream = dataset[0]
            message_header.dataset_size = dataset[1]
        return message_header

    def __send_bytes(self, id, exposed_path,data, user_meta=None,dataset=None, stream="default", ingest_mode = DEFAULT_INGEST_MODE,callback=None, auto_id = False):
        cdef MessageHeader message_header = self.create_message_header(id,exposed_path,user_meta,dataset,ingest_mode,auto_id)
        message_header.data_size = len(data)
        err = self.c_producer.get().Send__(message_header, data_pointer_bytes(data), ingest_mode, _bytes(stream),
            unwrap_callback_with_memory(<RequestCallbackCythonMemory>self.c_callback_bytesaddr,
             <void*>self,<void*>callback, <void*>data))
        if err:
            throw_exception(err)
        Py_XINCREF(<PyObject*>data)
        if callback != None:
            Py_XINCREF(<PyObject*>callback)
        return
    def send_stream_meta(self, metadata, mode = 'replace', upsert = True, stream='default', callback=None):
        """
         :param stream: stream name, default "default"
         :type stream: string
         :param metadata: beamtime metadata in JSON format
         :type metadata: string
         :param mode: send mode
         :type mode: string
         :param upsert: send mode
         :type upsert: bool
         :param callback: callback function, default None
         :type callback: callback(info,err), where info - json string with event header that was used to send data and response, err - error string or None
         :raises:
            AsapoWrongInputError: wrong input (authorization, ...)
            AsapoProducerError: other error
        """
        cdef MetaIngestMode mode_c
        mode_c.op = mode_to_c(mode)
        mode_c.upsert = upsert
        err = self.c_producer.get().SendStreamMetadata(_bytes(metadata), mode_c,_bytes(stream),
              unwrap_callback(<RequestCallbackCython>self.c_callback, <void*>self,<void*>callback if callback != None else NULL))
        if err:
            throw_exception(err)
        if callback != None:
            Py_XINCREF(<PyObject*>callback)
    def send_beamtime_meta(self, metadata, mode = 'replace', upsert = True, callback=None):
        """
         :param metadata: beamtime metadata in JSON format
         :type metadata: string
         :param mode: send mode
         :type mode: string
         :param upsert: send mode
         :type upsert: bool
         :param callback: callback function, default None
         :type callback: callback(info,err), where info - json string with event header that was used to send data and response, err - error string or None
         :raises:
            AsapoWrongInputError: wrong input (authorization, ...)
            AsapoProducerError: other error
        """
        cdef MetaIngestMode mode_c
        mode_c.op = mode_to_c(mode)
        mode_c.upsert = upsert
        err = self.c_producer.get().SendBeamtimeMetadata(_bytes(metadata), mode_c,
              unwrap_callback(<RequestCallbackCython>self.c_callback, <void*>self,<void*>callback if callback != None else NULL))
        if err:
            throw_exception(err)
        if callback != None:
            Py_XINCREF(<PyObject*>callback)
    def send(self, uint64_t id, exposed_path, data, user_meta=None, dataset=None, ingest_mode = DEFAULT_INGEST_MODE,
     stream = "default", callback=None, auto_id = False):
        """
         :param id: unique data id
         :type id: int
         :param exposed_path: Path which will be exposed to consumers
         :type exposed_path: string
         :param data: data to send
         :type data: contiguous numpy or bytes array, can be None for INGEST_MODE_TRANSFER_METADATA_ONLY ingest mode
         :param user_meta: user metadata, default None
         :type user_meta: JSON string
         :param dataset: a tuple with two int values (dataset substream id, amount of dataset substreams), default None
         :type dataset: tuple
         :param ingest_mode: ingest mode flag
         :type ingest_mode: int
         :param stream: stream name, default "default"
         :type stream: string
         :param callback: callback function, default None
         :type callback: callback(info,err), where info - json string with event header that was used to send data and response, err - error string or None
         :param auto_id: a flag to assign ids automatically, id must be 0 when auto_id = True
         :type auto_id: Boolean
         :raises:
            AsapoWrongInputError: wrong input (authorization, meta, ...)
            AsapoProducerError: actually should not happen
        """
        if type(data) == np.ndarray or data == None:
            self.__send_np_array(id,exposed_path,data,user_meta,dataset,stream,ingest_mode,callback,auto_id)
        elif type(data) == bytes:
            self.__send_bytes(id,exposed_path,data,user_meta,dataset,stream,ingest_mode,callback,auto_id)
        else:
            raise(AsapoProducerError("wrong data type: " + str(type(data))))
    def send_stream_finished_flag(self, stream, uint64_t last_id, next_stream = None, callback = None):
        """
         :param stream: stream name
         :type stream: string
         :param id: id of the last record
         :param next_stream: name of the next stream or None
         :type stream: string
         :param callback: callback function, default None
         :type callback: callback(info,err), where info - json string with event header that was used to send data and response, err - error string or None
         :raises:
            AsapoWrongInputError: wrong input (authorization, meta, ...)
            AsapoProducerError: actually should not happen
        """
        err = self.c_producer.get().SendStreamFinishedFlag(_bytes(stream), last_id,_bytes(next_stream) if next_stream != None else "",
        unwrap_callback(<RequestCallbackCython>self.c_callback, <void*>self,<void*>callback if callback != None else NULL))
        if err:
            throw_exception(err)
        if callback != None:
            Py_XINCREF(<PyObject*>callback)

    def delete_stream(self, stream = 'default', uint64_t timeout_ms = 1000,bool error_on_not_exist = True):
        """
         :param stream: stream name
         :type stream: string
         :param timeout_ms: timeout in milliseconds
         :type timeout_ms: int
         :param error_on_not_exist: will emit AsapoWrongInputError if set to true and tries to delete non-existing stream
         :type error_on_not_exist: bool
         :raises:
            AsapoWrongInputError: wrong input (authorization, ...)
            AsapoTimeoutError: request not finished for a given timeout
            AsapoProducerError: other errors
        """
        cdef Error err
        cdef DeleteStreamOptions opts
        cdef string b_stream = _bytes(stream)
        opts.error_on_not_exist = error_on_not_exist
        with nogil:
            err = self.c_producer.get().DeleteStream(b_stream,timeout_ms,opts)
        if err:
            throw_exception(err)
    def get_stream_meta(self,stream = 'default', uint64_t timeout_ms = 1000):
        """
         :param stream: stream name
         :type stream: string
         :param timeout_ms: timeout in milliseconds
         :type timeout_ms: int
         :raises:
            AsapoWrongInputError: wrong input (authorization, ...)
            AsapoTimeoutError: request not finished for a given timeout
            AsapoProducerError: other errors
        """
        cdef Error err
        cdef string res
        cdef string b_stream = _bytes(stream)
        with nogil:
            res = self.c_producer.get().GetStreamMeta(b_stream,timeout_ms,&err)
        if err:
            throw_exception(err)
        return json.loads(_str(res) or 'null')
    def get_beamtime_meta(self, uint64_t timeout_ms = 1000):
        """
         :param timeout_ms: timeout in milliseconds
         :type timeout_ms: int
         :raises:
            AsapoWrongInputError: wrong input (authorization, ...)
            AsapoTimeoutError: request not finished for a given timeout
            AsapoProducerError: other errors
        """
        cdef Error err
        cdef string res
        with nogil:
            res = self.c_producer.get().GetBeamtimeMeta(timeout_ms,&err)
        if err:
            throw_exception(err)
        return json.loads(_str(res) or 'null')
    def stream_info(self, stream = 'default', uint64_t timeout_ms = 1000):
        """
         :param stream: stream name
         :type stream: string
         :param timeout_ms: timeout in milliseconds
         :type timeout_ms: int
         :raises:
            AsapoWrongInputError: wrong input (authorization, ...)
            AsapoTimeoutError: request not finished for a given timeout
            AsapoProducerError: other errors
        """
        cdef Error err
        cdef StreamInfo info
        cdef string b_stream = _bytes(stream)
        with nogil:
            info = self.c_producer.get().GetStreamInfo(b_stream,timeout_ms,&err)
        if err:
            throw_exception(err)
        return json.loads(_str(info.Json()))

    def last_stream(self, uint64_t timeout_ms = 1000):
        """
         :param timeout_ms: timeout in seconds
         :type timeout_ms: int
         :raises:
            AsapoWrongInputError: wrong input (authorization, ...)
            AsapoTimeoutError: request not finished for a given timeout
            AsapoProducerError: other errors
        """
        cdef Error err
        cdef StreamInfo info
        with nogil:
            info = self.c_producer.get().GetLastStream(timeout_ms,&err)
        if err:
            throw_exception(err)
        return json.loads(_str(info.Json()))
    def send_file(self, uint64_t id, local_path, exposed_path, user_meta=None, dataset=None,
        ingest_mode = DEFAULT_INGEST_MODE, stream = "default", callback=None, auto_id = False):
        """
         :param id: unique data id
         :type id: int
         :param local_path: Path to file to send
         :type local_path: string
         :param exposed_path: Path which will be exposed to consumers
         :type exposed_path: string
         :param user_meta: user metadata, default None
         :type user_meta: JSON string
         :param dataset: a tuple with two int values (dataset id, dataset size), default None
         :type dataset: tuple
         :param ingest_mode: ingest mode flag
         :type ingest_mode: int
         :param stream: stream name, default "default"
         :type stream: string
         :param callback: callback function, default None
         :type callback: callback(info,err), where info - json string with event header that was used to send data and response, err - error string or None
         :param auto_id: a flag to assign ids automatically, id must be 0 when auto_id = True
         :type auto_id: Boolean
         :raises:
            AsapoWrongInputError: wrong input (authorization, meta, ...)
            AsapoLocalIOError: problems reading file to send
            AsapoProducerError: actually should not happen
        """

        cdef MessageHeader message_header = self.create_message_header(id,exposed_path,user_meta,dataset,ingest_mode,auto_id)
        message_header.data_size = 0
        err = self.c_producer.get().SendFile(message_header, _bytes(local_path), ingest_mode, _bytes(stream),
            unwrap_callback(<RequestCallbackCython>self.c_callback, <void*>self,<void*>callback if callback != None else NULL))
        if err:
            throw_exception(err)

        if callback != None:
            Py_XINCREF(<PyObject*>callback)

        return
    def get_requests_queue_size(self):
        return self.c_producer.get().GetRequestsQueueSize()
    def get_requests_queue_volume_mb(self):
        return self.c_producer.get().GetRequestsQueueVolumeMb()
    def enable_new_monitoring_api_format(self, bool enabled):
        cdef Error err
        with nogil:
            err = self.c_producer.get().EnableNewMonitoringApiFormat(enabled)
        if err:
            throw_exception(err)
        return
    def set_requests_queue_limits(self,uint64_t size = 0, uint64_t volume_mb = 0):
        return self.c_producer.get().SetRequestsQueueLimits(size,volume_mb)
    def wait_requests_finished(self,timeout_ms):
        """
         :param timeout_ms: timeout in milliseconds
         :type timeout_ms: int
         :raises:
            AsapoTimeoutError: requests not finished for a given timeout
        """
        cdef Error err
        cdef uint64_t timeout = timeout_ms
        with nogil:
            err = self.c_producer.get().WaitRequestsFinished(timeout)
        if err:
            throw_exception(err)
        return
    cdef void c_callback_python(self,py_callback, data, RequestCallbackPayload& payload, Error& err):
        if py_callback != None:
          info_str = _str(payload.original_header.Json())
          info = json.loads(info_str)
          info['server_response'] = payload.response
          if payload.data.get() != NULL:
             payload.data.release()
             info['data'] = data
          if err:
            py_err = python_exception_from_error(err)
          else:
            py_err = None
          py_callback(info,py_err)
          Py_XDECREF(<PyObject*>py_callback)

    cdef void c_callback(self,py_callback, RequestCallbackPayload payload, Error err) with gil:
        self.c_callback_python(py_callback,None,payload,err)

    cdef void c_callback_ndarr(self,py_callback,nd_array,RequestCallbackPayload payload, Error err) with gil:
        self.c_callback_python(py_callback,nd_array,payload,err)
        if nd_array is not None:
          if nd_array.base is not None:
            Py_XDECREF(<PyObject*>nd_array.base)
          else:
            Py_XDECREF(<PyObject*>nd_array)

    cdef void c_callback_bytesaddr(self,py_callback,bytes_array,RequestCallbackPayload payload, Error err) with gil:
        self.c_callback_python(py_callback,bytes_array,payload,err)
        if bytes_array is not None:
            Py_XDECREF(<PyObject*>bytes_array)
    def cleanup(self):
        with  nogil:
            if self.c_producer.get() is not NULL:
                self.c_producer.get().StopThreads__()
    @staticmethod
    def __create_producer(endpoint,type,instance_id,pipeline_step,beamtime_id,beamline,data_source,token,nthreads,timeout_ms):
        pyProd = PyProducer()
        cdef Error err
        cdef SourceType source_type
        err = GetSourceTypeFromString(type,&source_type)
        if err:
            throw_exception(err)
        cdef SourceCredentials source
        source.instance_id = instance_id
        source.pipeline_step = pipeline_step
        source.beamtime_id = beamtime_id
        source.beamline = beamline
        source.user_token = token
        source.data_source = data_source
        source.type = source_type
        pyProd.c_producer = Producer.Create(endpoint,nthreads,RequestHandlerType_Tcp,source,timeout_ms,&err)
        if err:
            throw_exception(err)
        return pyProd

def create_producer(endpoint,type,instance_id,pipeline_step,beamtime_id,beamline,data_source,token,nthreads,timeout_ms):
    """
         :param endpoint: server endpoint (url:port)
         :type endpoint: string
         :param type: source type, "raw" to write to "raw" folder in beamline filesystem,"processed" to write to "processed" folder in core filesystem
         :type type: string
         :param instance_id: instance id, can be "auto", will create a combination out of hostname and pid
         :type instance_id: string
         :param pipeline_step: pipeline step id, can be "auto", "DefaultStep" is used then
         :type pipeline_step: string
         :param beamline: beamline name, can be "auto" if beamtime_id is given
         :type beamline: string
         :param data_source: name of the data source that produces data
         :type data_source: string
         :param token: authorization token
         :type token: string
         :param nthreads: ingest mode flag
         :type nthreads: int
         :param timeout_ms: send requests timeout in milliseconds
         :type timeout_ms: int
         :raises:
            AsapoWrongInputError: wrong input (number of threads, ,,,)
            AsapoProducerError: actually should not happen
    """
    return PyProducer.__create_producer(_bytes(endpoint),_bytes(type),_bytes(instance_id),_bytes(pipeline_step),_bytes(beamtime_id),_bytes(beamline),_bytes(data_source),_bytes(token),nthreads,timeout_ms)


__version__ = "@PYTHON_ASAPO_VERSION@@ASAPO_VERSION_COMMIT@"
