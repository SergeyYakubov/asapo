---
title: Datasets
---


import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

The messages in the stream can be multi-parted. If you have several producers (e.g. sub-detectors) that produces several parts of the single message, you can use datasets to assemble a single message from several parts.

## Dataset Producer

Here is the code snippet that can be used to produce a three-parted dataset. The full usable example can be found in git repository.

<Tabs
  groupId="language"
  defaultValue="python"
  values={[
    { label: 'Python', value: 'python', },
    { label: 'C++', value: 'cpp', },
  ]
}>
<TabItem value="python">

```python content="./versioned_examples/version-21.12.0/python/produce_dataset.py" snippetTag="dataset"
```

</TabItem>

<TabItem value="cpp">

```cpp content="./versioned_examples/version-21.12.0/cpp/produce_dataset.cpp" snippetTag="dataset"
```

</TabItem>
</Tabs>

You should see the "successfuly sent" message in the logs, and the file should appear in the corresponding folder (by default in ```/var/tmp/asapo/global_shared/data/test_facility/gpfs/test/2019/data/asapo_test```)

## Dataset Consumer

Here is the snippet that can be used to consume a dataset. The full example is also in git.

<Tabs
  groupId="language"
  defaultValue="python"
  values={[
    { label: 'Python', value: 'python', },
    { label: 'C++', value: 'cpp', },
  ]
}>
<TabItem value="python">

```python content="./versioned_examples/version-21.12.0/python/consume_dataset.py" snippetTag="dataset"
```

</TabItem>

<TabItem value="cpp">

```cpp content="./versioned_examples/version-21.12.0/cpp/consume_dataset.cpp" snippetTag="dataset"
```

</TabItem>
</Tabs>

The details about the received dataset should appear in the logs, together with the message "stream finished" (if the "finished" flag was sent for the stream). The "stream ended" message will appear for non-finished streams, but may also mean that the stream does not exist (or was deleted).
