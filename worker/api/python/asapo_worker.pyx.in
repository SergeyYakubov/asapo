#distutils: language=c++

cimport asapo_worker
import numpy as np
cimport numpy as np
import json
from cpython.version cimport PY_MAJOR_VERSION

np.import_array()

cdef str _str(b):
    if PY_MAJOR_VERSION < 3:
        return b
    return b.decode("utf-8")

cdef bytes _bytes(s):
    if type(s) is bytes:
        return s

    elif isinstance(s, unicode):
        return (<unicode>s).encode('utf-8')

    else:
        raise TypeError("Could not convert to unicode.")


cdef class PyDataBroker:
    cdef DataBroker* c_broker
    def _op(self, op, group_id, meta_only,id):
        cdef FileInfo info
        cdef FileData data
        cdef Error err
        cdef np.npy_intp dims[1]
        if op == "next":
            err =  self.c_broker.GetNext(&info, _bytes(group_id), <FileData*>NULL if meta_only else &data)
        elif op == "last":
            err =  self.c_broker.GetLast(&info,_bytes(group_id), <FileData*>NULL if meta_only else &data)
        elif op == "id":
            err =  self.c_broker.GetById(id, &info,_bytes(group_id), <FileData*>NULL if meta_only else &data)
        err_str = _str(GetErrorString(&err))
        if err_str.strip():
            return None,None,err_str
        info_str = _str(info.Json())
        meta = json.loads(info_str)
        if meta_only:
            return None,meta,None
        cdef char* ptr = <char*> data.release()
        dims[0] = meta['size']
        arr =  np.PyArray_SimpleNewFromData(1, dims, np.NPY_BYTE, ptr)
        return arr,meta,None
    def get_next(self, group_id, meta_only = True):
        return self._op("next",group_id,meta_only,0)
    def get_last(self, group_id, meta_only = True):
        return self._op("last",group_id,meta_only,0)
    def get_by_id(self,id,group_id,meta_only = True):
        return self._op("id",group_id,meta_only,id)
    def retrieve_data(self,meta):
        json_str = json.dumps(meta)
        cdef FileInfo info
        if not info.SetFromJson(_bytes(json_str)):
            return None,"wrong metadata"
        cdef Error err
        cdef FileData data
        err =  self.c_broker.RetrieveData(&info, &data)
        err_str = _str(GetErrorString(&err))
        if err_str.strip():
            return None,err_str
        cdef np.npy_intp dims[1]
        dims[0] = meta['size']
        cdef char* ptr = <char*> data.release()
        arr =  np.PyArray_SimpleNewFromData(1, dims, np.NPY_BYTE, ptr)
        return arr,None


    def get_ndatasets(self):
        cdef Error err
        size =  self.c_broker.GetNDataSets(&err)
        err_str = _str(GetErrorString(&err))
        if err_str.strip():
            return None,err_str
        else:
            return size,None
    def reset_counter(self,group_id):
        cdef Error err
        err =  self.c_broker.ResetCounter(_bytes(group_id))
        err_str = _str(GetErrorString(&err))
        if err_str.strip():
            return err_str
        else:
            return None
    def generate_group_id(self):
        cdef Error err
        cdef string group_id
        group_id = self.c_broker.GenerateNewGroupId(&err)
        err_str = _str(GetErrorString(&err))
        if err_str.strip():
            return None, err_str
        else:
            return _str(group_id), None
    def query_images(self,query):
        cdef Error err
        cdef FileInfos file_infos
        file_infos = self.c_broker.QueryImages(_bytes(query),&err)
        err_str = _str(GetErrorString(&err))
        if err_str.strip():
            return None, err_str
        else:
            json_list = []
            for fi in file_infos:
                json_list.append(json.loads(_str(fi.Json())))
            return json_list, None
    def _op_dataset(self, op, group_id, id):
        cdef FileInfos file_infos
        cdef DataSet dataset
        cdef Error err
        if op == "next":
            dataset = self.c_broker.GetNextDataset(_bytes(group_id),&err)
        elif op == "last":
            dataset = self.c_broker.GetLastDataset(_bytes(group_id),&err)
        elif op == "id":
            dataset = self.c_broker.GetDatasetById(id,_bytes(group_id),&err)
        err_str = _str(GetErrorString(&err))
        if err_str.strip():
            return None, None, err_str
        else:
            json_list = []
            for fi in dataset.content:
                json_list.append(json.loads(_str(fi.Json())))
            return dataset.id, json_list, None


    def get_next_dataset(self, group_id):
        return self._op_dataset("next",group_id,0)
    def get_last_dataset(self, group_id):
        return self._op_dataset("last",group_id,0)
    def get_dataset_by_id(self, id, group_id):
        return self._op_dataset("id",group_id,id)


    def get_beamtime_meta(self):
            cdef Error err
            cdef string meta_str
            meta_str = self.c_broker.GetBeamtimeMeta(&err)
            err_str = _str(GetErrorString(&err))
            if err_str.strip():
                return None, err_str
            else:
                meta = json.loads(_str(meta_str))
                del meta['_id']
                return meta, None

cdef class PyDataBrokerFactory:
    cdef DataBrokerFactory c_factory
    def __cinit__(self):
        self.c_factory = DataBrokerFactory()
    def create_server_broker(self,server_name,source_path,beamtime_id,token,timeout):
        cdef Error err
        cdef unique_ptr[DataBroker] c_broker = self.c_factory.CreateServerBroker(server_name,source_path,beamtime_id,token,&err)
        broker = PyDataBroker()
        broker.c_broker =  c_broker.release()
        broker.c_broker.SetTimeout(timeout)
        err_str = GetErrorString(&err)
        if err_str.strip():
            return None,err_str
        else:
            return broker,err_str

def create_server_broker(server_name,source_path,beamtime_id,token,timeout):
    factory = PyDataBrokerFactory()
    return factory.create_server_broker(_bytes(server_name),_bytes(source_path),_bytes(beamtime_id),_bytes(token),timeout)


__version__ = "@ASAPO_VERSION_PYTHON@"
